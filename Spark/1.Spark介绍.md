# Spark 介绍

## 1. Spark 是什么

Apache Spark 是专为大规模数据处理而设计的快速通用的计算引擎。

Spark拥有Hadoop MapReduce所具有的优点；但不同于MapReduce的是Job中间输出结果可以保存在内存中，从而不再需要读写HDFS，因此Spark能更好地适用于数据挖掘与机器学习等需要迭代的MapReduce的算法。

## 2. Spark 与 MapReduce 的区别

Spark 基于内存计算是 Hadoop 的 100 倍

Spark 基于磁盘计算是 Hadoop 的 10 倍

都是分布式计算框架，Spark基于内存，MR基于HDFS。

Spark处理数据的能力一般是MR的十倍以上，Spark中除了基于内存计算外，还有DAG有向无环图来切分任务的执行先后顺序。

## 3. Spark 四大组件

1. Spark SQL

2. Spark Streaming

3. Spark MLlib

4. GraphX

## 4. Spark运行模式

1. Local

多用于本地测试，如在eclipse，idea中写程序测试等。

2. Standalone

Standalone 是 Spark 自带的一个资源调度框架，它支持完全分布式。

3. Yarn

Hadoop 生态圈里面的一个资源调度框架，Spark 也是可以基于 Yarn 来计算的。

要基于 Yarn 来进行资源调度，必须实现 AppalicationMaster 接口，Spark 实现了这个接口，所以可以基于 Yarn。

4. Mesos

资源调度框架。


